{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_pre = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  \n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(Y + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels \n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(-1, x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_resnet(resnet_block_num, resnet_block, FlattenLayer, GlobalAvgPool2d):\n",
    "    \n",
    "    net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    resnet_block_num = 1\n",
    "\n",
    "    if resnet_block_num == 1:\n",
    "        net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "        net.add_module(\"global_avg_pool\", GlobalAvgPool2d()) \n",
    "        net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(64, 1000))) \n",
    "    elif resnet_block_num == 2:\n",
    "        net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "        net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "        net.add_module(\"global_avg_pool\", GlobalAvgPool2d()) \n",
    "        net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(128, 1000))) \n",
    "    elif resnet_block_num == 3:\n",
    "        net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "        net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "        net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "        net.add_module(\"global_avg_pool\", GlobalAvgPool2d()) \n",
    "        net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(256, 1000))) \n",
    "    else:\n",
    "        net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "        net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "        net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "        net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))   \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = resnet18_pre.state_dict()\n",
    "nonpretrained_dict = resnet.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in pretrained_dict.items():\n",
    "    if name == 'layer3.0.conv1.weight':\n",
    "        break\n",
    "    else:\n",
    "        nonpretrained_dict[name] = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.load_state_dict(nonpretrained_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_RNN1(nn.Module):\n",
    "    def __init__(self, extra): #extra = NUM_PIECES\n",
    "        super(Graph_RNN1, self).__init__()\n",
    "        self.linear1 = nn.Linear(1000 + extra, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(64, 128, 4)\n",
    "        self.linear2 = nn.Linear(128, 32)\n",
    "        self.linear3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.state = None\n",
    "    def forward(self, x, state):\n",
    "        linear1_output = self.relu(self.linear1(x))\n",
    "        lstm_output, self.state = self.lstm(linear1_output.view(1, 1, 64), state)\n",
    "        linear2_output = self.relu(self.linear2(lstm_output.view(-1, lstm_output.shape[-1])))\n",
    "        linear3_output = self.sigmoid(self.linear3(linear2_output))\n",
    "        return linear3_output, self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_RNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Graph_RNN2, self).__init__()\n",
    "        self.linear1 = nn.Linear(1, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(8, 16, 4)\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.linear3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.state = None\n",
    "    def forward(self, x, state):\n",
    "        linear1_output = self.relu(self.linear1(x))\n",
    "        lstm_output, self.state = self.lstm(linear1_output.view(1, 1, 8), state)\n",
    "        linear2_output = self.relu(self.linear2(lstm_output.view(-1, lstm_output.shape[-1])))\n",
    "        linear3_output = self.sigmoid(self.linear3(linear2_output))\n",
    "        return linear3_output, self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extra = 128\n",
    "RNN1 = Graph_RNN1(extra) \n",
    "RNN2 = Graph_RNN2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize = True\n",
    "\n",
    "if initialize == True:\n",
    "    for name, param in RNN1.named_parameters(): \n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.25)\n",
    "        else:\n",
    "            if 'lstm' in name:\n",
    "                nn.init.xavier_uniform_(param, gain=nn.init.calculate_gain('sigmoid'))\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(param, gain=nn.init.calculate_gain('relu'))\n",
    "    for name, param in RNN2.named_parameters(): \n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.25)\n",
    "        else:\n",
    "            if 'lstm' in name:\n",
    "                nn.init.xavier_uniform_(param, gain=nn.init.calculate_gain('sigmoid'))\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(param, gain=nn.init.calculate_gain('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = False\n",
    "epoch_num = 10\n",
    "NUM_PIECES_load = 8\n",
    "\n",
    "if pre_train == True:\n",
    "    resnet.load_state_dict(torch.load(r'/home/heu/wmh/model/CNN_' + str(NUM_PIECES_load) + r'_' \n",
    "                                        + str(epoch_num) + r'.pt'))\n",
    "    RNN1.load_state_dict(torch.load(r'/home/heu/wmh/model/RNN1_' + str(NUM_PIECES_load) + r'_' \n",
    "                                        + str(epoch_num) + r'.pt'))\n",
    "    RNN2.load_state_dict(torch.load(r'/home/heu/wmh/model/RNN2_' + str(NUM_PIECES_load) + r'_' \n",
    "                                        + str(epoch_num) + r'.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(image1, image2): \n",
    "    kernel = np.ones((10, 10))\n",
    "    erosion = cv2.erode(image2, kernel, iterations = 3)\n",
    "    target = ((image2 - erosion) / 255) * image1\n",
    "    target.resize(256, 256, 3)\n",
    "    transform_GY = transforms.ToTensor()\n",
    "    batch_size = 1\n",
    "    ans = transform_GY(target).view(1, 3, 256, 256)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajm(NUM_PIECES, ajmatrix): \n",
    "    ans = torch.zeros(NUM_PIECES, NUM_PIECES)\n",
    "    cur_tar = 0\n",
    "    for i in range(NUM_PIECES):\n",
    "        for j in range(NUM_PIECES):\n",
    "            if ajmatrix[cur_tar] == '1':\n",
    "                ans[j][i] = 1\n",
    "            cur_tar += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_ajm(temp_index, adjacency_matrix, NUM_PIECES):\n",
    "    ans = torch.zeros(NUM_PIECES, NUM_PIECES)\n",
    "    cur_tar = 0\n",
    "    j = 0\n",
    "    for i in range(NUM_PIECES):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        for j in range(i):\n",
    "            temp_list = [temp_index[i]]\n",
    "            temp_list.append(temp_index[j])\n",
    "            temp_list.sort()\n",
    "            ans[j][i] = adjacency_matrix[temp_list[0]][temp_list[1]]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_pieces(path, NUM_PIECES, train):\n",
    "    if train == True: \n",
    "        start = 1\n",
    "        end = 45\n",
    "    else:\n",
    "        start = 45\n",
    "        end = 51\n",
    "    \n",
    "    shuffle_list = list(range(start, end))\n",
    "    random.shuffle(shuffle_list)\n",
    "    shuffle = False\n",
    "    if train == True and shuffle == True:\n",
    "        iteration = 4 \n",
    "        shuffle_dict = []\n",
    "        for i in range(iteration):\n",
    "            list_a = list(range(NUM_PIECES))\n",
    "            list_b = list(range(NUM_PIECES))\n",
    "            list_c = list(range(NUM_PIECES))\n",
    "            list_d = list(range(NUM_PIECES))\n",
    "            random.shuffle(list_b)\n",
    "            random.shuffle(list_c)\n",
    "            random.shuffle(list_d)\n",
    "            shuffle_dict.append(list_a)\n",
    "            shuffle_dict.append(list_b)\n",
    "            shuffle_dict.append(list_c)\n",
    "            shuffle_dict.append(list_d)\n",
    "        \n",
    "    for SHEET_INDEX in shuffle_list:\n",
    "        if SHEET_INDEX == 7 or SHEET_INDEX == 27 or SHEET_INDEX == 48:  \n",
    "            continue\n",
    "        SIDE = ['back', 'front']\n",
    "        for side in SIDE:\n",
    "            dataset_pieces_data = []\n",
    "            for image_index in range(1, NUM_PIECES + 1):\n",
    "                if image_index >= 10:\n",
    "                    index = '00' + str(image_index)\n",
    "                else:\n",
    "                    index = '000' + str(image_index)\n",
    "                # path = r'E:\\data\\data'\n",
    "                final_path = path + r'/sheet' + str(SHEET_INDEX) + '//' + str(NUM_PIECES) + r'pieces'\\\n",
    "                + '//' + side + r'/final'\n",
    "                image = cv2.imread(final_path + r'/IMG_' + index + r'_erode.png')\n",
    "                image.resize(256, 256, 3)\n",
    "                transform_GY = transforms.ToTensor()\n",
    "                batch_size = 1\n",
    "                ans = transform_GY(image).view(1, 3, 256, 256)\n",
    "                dataset_pieces_data.append(ans)\n",
    "            fid = open(final_path + '/groundtruth.txt', 'r')\n",
    "            ajmatrix = fid.read()\n",
    "            fid.close()\n",
    "            adjacency_matrix = ajm(NUM_PIECES, ajmatrix)\n",
    "            yield dataset_pieces_data, adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/home/heu/wmh/data/data'\n",
    "dataset8_train = dataset_pieces(path, 8, True)\n",
    "dataset8_test = dataset_pieces(path, 8, False)\n",
    "dataset16_train = dataset_pieces(path, 16, True)\n",
    "dataset16_test = dataset_pieces(path, 16, False)\n",
    "dataset_train = {'8':dataset8_train, '16':dataset16_train}\n",
    "dataset_test = {'8':dataset8_test, '16':dataset16_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "loss = nn.CrossEntropyLoss()  \n",
    "lr_1 = 0.0001    #0.0001\n",
    "lr_2 = 0.00001  #0.000001\n",
    "lr_3 = 0.0001    #0.0001\n",
    "resnetoptim = torch.optim.AdamW(resnet.parameters(), lr_1)  \n",
    "RNN1optim = torch.optim.AdamW(RNN1.parameters(), lr_2)\n",
    "RNN2optim = torch.optim.AdamW(RNN2.parameters(), lr_3)\n",
    "optim = [resnetoptim, RNN1optim, RNN2optim]\n",
    "resnet_lr_scheduler = torch.optim.lr_scheduler.CyclicLR(resnetoptim, lr_1, lr_1 * 10, cycle_momentum = False)\n",
    "RNN1_lr_scheduler = torch.optim.lr_scheduler.CyclicLR(RNN1optim, lr_2, lr_2 * 10, cycle_momentum = False)\n",
    "RNN2_lr_scheduler = torch.optim.lr_scheduler.CyclicLR(RNN2optim, lr_3, lr_3 * 10, cycle_momentum = False)\n",
    "lr_scheduler = [resnet_lr_scheduler, RNN1_lr_scheduler, RNN2_lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device): \n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta / norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_tensor(rnn2_output):\n",
    "    ans = torch.tensor(rnn2_output.shape, dtype = torch.float, device = \n",
    "                       torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    ans = ans.copy(rnn2_output)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset_pieces, cnn, rnn1, rnn2, NUM_PIECES, device, extra, path):\n",
    "    cnn = cnn.to(device)\n",
    "    rnn1 = rnn1.to(device)\n",
    "    rnn2 = rnn2.to(device)\n",
    "    acc_sum = 0\n",
    "    data_sum = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    with torch.no_grad():\n",
    "        train = False\n",
    "        for x, y in dataset_pieces:\n",
    "            n = 0\n",
    "            for i in range(1, NUM_PIECES):\n",
    "                n += i\n",
    "            data_sum += n\n",
    "            pre_ajm = torch.zeros(NUM_PIECES, NUM_PIECES, device = device)\n",
    "            y = y.to(device)\n",
    "            rnn1_state = None \n",
    "            rnn2_state = None\n",
    "            for i in range(NUM_PIECES):\n",
    "                cnn1_output = cnn(x[i].type(torch.float).to(device))\n",
    "                if i == 0:\n",
    "                    cnn_ajm = torch.zeros(1, extra, dtype = torch.float, device = device)\n",
    "                    cnn1_output = torch.cat((cnn1_output, cnn_ajm), 1)\n",
    "                else:\n",
    "                    cnn_ajm = torch.zeros(1, extra, dtype = torch.float, device = device)\n",
    "                    for j in range(NUM_PIECES):  \n",
    "                        cnn_ajm[0][j] = pre_ajm[j][i - 1]\n",
    "                    cnn1_output = torch.cat((cnn1_output, cnn_ajm), 1)\n",
    "                rnn1_output, rnn1_state = rnn1(cnn1_output, rnn1_state)\n",
    "                rnn2_output, rnn2_state = rnn2(rnn1_output, rnn2_state)\n",
    "                if i != 0:\n",
    "                    first = True\n",
    "                    count = i\n",
    "                    while count > 0:\n",
    "                        count -= 1\n",
    "                        if first:\n",
    "                            first = False\n",
    "                            pre_ajm[count][i] = 1 if rnn2_output.sum().item() >= 0.5 else 0\n",
    "                        else:\n",
    "                            rnn2_output, rnn2_state = rnn2(rnn2_output, rnn2_state)\n",
    "                            pre_ajm[count][i] = 1 if rnn2_output.sum().item() >= 0.5 else 0\n",
    "            for i in range(NUM_PIECES - 1):\n",
    "                for j in range(i + 1, NUM_PIECES):\n",
    "                    if pre_ajm[i][j] == y[i][j]:\n",
    "                        acc_sum += 1\n",
    "                    if pre_ajm[i][j] == 1:\n",
    "                        if y[i][j] == 1:\n",
    "                            TP += 1  #TP\n",
    "                        else:\n",
    "                            FP += 1  #FN\n",
    "                    else:\n",
    "                        if y[i][j] == 1:\n",
    "                            FN += 1  #FP\n",
    "                        else:\n",
    "                            TN += 1  #TN\n",
    "    return acc_sum / data_sum, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_pieces, cnn, rnn1, rnn2, num_epochs, device, opitm, lr_scheduler, extra, theta, path, evaluate_model):\n",
    "    cnn = cnn.to(device)\n",
    "    rnn1 = rnn1.to(device)\n",
    "    rnn2 = rnn2.to(device)\n",
    "    loss = nn.BCELoss()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        #if epoch % 10 == 0:\n",
    "            #torch.save(cnn.state_dict(), r'/home/heu/wmh/model/CNN_' + str(NUM_PIECES) + r'_' + str(epoch) + r'.pt')\n",
    "            #torch.save(rnn1.state_dict(), r'/home/heu/wmh/model/RNN1_' + str(NUM_PIECES) + r'_' + str(epoch) + r'.pt')\n",
    "            #torch.save(rnn2.state_dict(), r'/home/heu/wmh/model/RNN2_' + str(NUM_PIECES) + r'_' + str(epoch) + r'.pt')\n",
    "\n",
    "        for NUM_PIECES in [8, 16]:\n",
    "            start = time.time()\n",
    "            sum_loss = 0\n",
    "            n = 0\n",
    "            for i in range(1, NUM_PIECES):\n",
    "                n += i\n",
    "            if NUM_PIECES == 8:\n",
    "                dataset_cur = dataset_pieces(path, 8, True)\n",
    "            else:\n",
    "                dataset_cur = dataset_pieces(path, 16, True)\n",
    "            for x, y in dataset_cur:\n",
    "                y = y.to(device)\n",
    "                rnn1_state = None \n",
    "                rnn2_state = None\n",
    "                for i in range(NUM_PIECES):\n",
    "                    cnn_input = x[i].type(torch.float).to(device)\n",
    "                    cnn_output = cnn(cnn_input)\n",
    "                    if i == 0:\n",
    "                        cnn_ajm = torch.zeros(1, extra, dtype = torch.float, device = device)\n",
    "                        cnn_output2 = torch.cat((cnn_output, cnn_ajm), 1)\n",
    "                    else:\n",
    "                        cnn_ajm = torch.zeros(1, extra, dtype = torch.float, device = device)\n",
    "                        for j in range(NUM_PIECES):\n",
    "                            cnn_ajm[0][j] = y[j][i - 1]\n",
    "                        cnn_output2 = torch.cat((cnn_output, cnn_ajm), 1)\n",
    "                    if rnn1_state != None:\n",
    "                        rnn1_state = (rnn1_state[0].detach(), rnn1_state[1].detach())\n",
    "                    if rnn2_state != None:\n",
    "                        rnn2_state = (rnn2_state[0].detach(), rnn2_state[1].detach())\n",
    "                    rnn1_output, rnn1_state = rnn1(cnn_output2, rnn1_state)\n",
    "                    rnn2_output, rnn2_state = rnn2(rnn1_output, rnn2_state)\n",
    "                    if i != 0:\n",
    "                        first = True\n",
    "                        count = i\n",
    "                        while count > 0:\n",
    "                            count -= 1\n",
    "                            if first:\n",
    "                                first = False\n",
    "                                cur_y = torch.tensor([y[count][i].item()], dtype = torch.float, device = device)\n",
    "                                l = loss(rnn2_output.view(-1), cur_y)\n",
    "                                sum_loss += l.item()\n",
    "                                for cur_optim in optim: \n",
    "                                    cur_optim.zero_grad()\n",
    "                                l.backward(retain_graph=True)\n",
    "                                grad_clipping(RNN1.parameters(), theta, device) \n",
    "                                grad_clipping(RNN2.parameters(), theta, device)\n",
    "                                for cur_optim in optim: \n",
    "                                    cur_optim.step()\n",
    "                                for scheduler in lr_scheduler:\n",
    "                                    scheduler.step()\n",
    "                            else:\n",
    "                                rnn2_input = torch.zeros(rnn2_output.shape, dtype = torch.float, device = device)\n",
    "                                rnn2_input[0][0] = rnn2_output[0][0].item()\n",
    "                                if rnn2_state != None:\n",
    "                                    rnn2_state = (rnn2_state[0].detach(), rnn2_state[1].detach())\n",
    "                                rnn2_output, rnn2_state = rnn2(rnn2_input, rnn2_state)\n",
    "                                cur_y = torch.tensor([y[count][i].item()], dtype = torch.float, device = device)\n",
    "                                l = loss(rnn2_output.view(-1), cur_y)\n",
    "                                sum_loss += l.item()\n",
    "                                optim[-1].zero_grad()\n",
    "                                l.backward()\n",
    "                                grad_clipping(RNN2.parameters(), theta, device)\n",
    "                                optim[-1].step()\n",
    "                                lr_scheduler[-1].step()\n",
    "                        rnn2_output, rnn2_state = rnn2(rnn2_output, rnn2_state)\n",
    "            if NUM_PIECES == 8:\n",
    "                loss_plt_8.append(sum_loss / n)\n",
    "                acc, TP, FP, TN, FN = evaluate_model(dataset_pieces(path, 8, False), cnn, rnn1, rnn2, NUM_PIECES, device, \n",
    "                                                 extra, path)\n",
    "                acc_plt_8.append(acc)\n",
    "            else:\n",
    "                loss_plt_16.append(sum_loss / n)\n",
    "                acc, TP, FP, TN, FN = evaluate_model(dataset_pieces(path, 16, False), cnn, rnn1, rnn2, NUM_PIECES, device, \n",
    "                                                 extra, path)\n",
    "                acc_plt_16.append(acc)\n",
    "\n",
    "            print('epoch: %d, NUM_PIECES: %d, loss: %.4f, time: %.1f, accuracy: %4f, TP: %d, FP: %d, TN: %d, FN: %d,' %\n",
    "                  (epoch, NUM_PIECES, sum_loss / n, time.time() - start, acc, TP, FP, TN, FN))\n",
    "            print('learning_rate1 : %.4f, learning_rate2 : %.6f, learning_rate3 : %.4f' % \n",
    "                  (optim[0].param_groups[0]['lr'], optim[1].param_groups[0]['lr'], optim[2].param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resnet = models.resnet()\n",
    "#RNN1 = Graph_RNN1(extra) \n",
    "#RNN2 = Graph_RNN2()\n",
    "#path = r'E:\\data\\data'\n",
    "#dataset8_train = dataset_pieces(path, 8, True)\n",
    "#dataset8_test = dataset_pieces(path, 8, False)\n",
    "#dataset16_train = dataset_pieces(path, 16, True)\n",
    "#dataset16_test = dataset_pieces(path, 16, False)\n",
    "#dataset_train = {'8':dataset8_train, '16':dataset16_train}\n",
    "#dataset_test = {'8':dataset8_test, '16':dataset16_test}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "#extra = 128\n",
    "#optim = [resnetoptim, RNN1optim, RNN2optim]\n",
    "#resnetoptim = torch.optim.Adam(resnet.parameters(), 0.0001)  \n",
    "#RNN1optim = torch.optim.Adam(RNN1.parameters(), 0.00001)\n",
    "#RNN2optim = torch.optim.Adam(RNN2.parameters(), 0.0001)\n",
    "theta = 1e-3\n",
    "NUM_PIECES = 8\n",
    "num_epochs = 500\n",
    "loss_plt_8 = []\n",
    "loss_plt_16 = []\n",
    "acc_plt_8 = []\n",
    "acc_plt_16 = []\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, NUM_PIECES: 8, loss: 56.3699, time: 44.0, accuracy: 0.678571, TP: 66, FP: 24, TN: 124, FN: 66,\n",
      "learning_rate1 : 0.0004, learning_rate2 : 0.000036, learning_rate3 : 0.0008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-57b8c4414e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_pieces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-88e1f45f3db8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataset_pieces, cnn, rnn1, rnn2, num_epochs, device, opitm, lr_scheduler, extra, theta, path, evaluate_model)\u001b[0m\n\u001b[1;32m     70\u001b[0m                                 \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                 \u001b[0moptim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                                 \u001b[0mgrad_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                                 \u001b[0moptim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wmh/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wmh/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    train_model(dataset_pieces, resnet, RNN1, RNN2, num_epochs, device, optim, lr_scheduler, extra, theta, path, evaluate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, num_epochs + 1))\n",
    "y1 = loss_plt_8\n",
    "y2 = loss_plt_16\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.legend(['loss_plt_8', 'loss_plt_16'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(r'/home/heu/wmh/1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = acc_plt_8\n",
    "y2 = acc_plt_16\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.legend(['acc_plt_8', 'acc_plt_16'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(r'/home/heu/wmh/2.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wmh_pytorch",
   "language": "python",
   "name": "wmh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
